\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}

\usepackage[brazil]{babel}   
%\usepackage[latin1]{inputenc}  
\usepackage[utf8]{inputenc}  
% UTF-8 encoding is recommended by ShareLaTex

\usepackage{mdframed}
\usepackage{minted}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
     
\sloppy

\title{Trabalho Prático 3 - Redes Neurais Artificiais}

\author{Hugo Araujo de Sousa}

\address{
  Computação Natural (2017/2) \\
  Departamento de Ciência da Computação \\
  Universidade Federal de Minas Gerais (UFMG)
  \email{hugosousa@dcc.ufmg.br}
}

\begin{document} 

\maketitle
     
\begin{resumo}
  Nesse trabalho são explorados conceitos relacionados a redes neurais,
  colocando-os em prática através da utilização da biblioteca Keras com Tensorflow, 
  que nos permite abordar um problema de classificação.
\end{resumo}

\section{INTRODUÇÃO}

Dentro da área de Computação Natural, o campo de Redes Neurais Artificiais
tem como objetivo a criação de modelos computacionais inspirados pelo
conhecimento que temos sobre como funciona o sistema nervoso, mais
especificamente, na estrutura e função dos neurônios no cérebro
\cite{clevalg}.

Dessa forma, uma Rede Neural Artificial é uma coleção de neurônios
artificiais que são conectados a fim de se realizar alguma computação
em padrões de entrada para gerar padrões de saída. Esses neurônios,
então, se adaptam, modificando sua estrutura interna ao longo do tempo.
Geralmente, essa modificação se dá através da atualização dos pesos
das conexões entre os neurônios da rede. Esse processo define o
aprendizado da rede neural, que então se torna, com o tempo, cada
vez mais adaptada na tarefa de gerar o padrão de saída correto de 
acordo com a entrada.

No trabalho em questão, usaremos a biblioteca Keras 
\footnote{\url{https://keras.io/}} com Tensorflow
\footnote{\url{https://www.tensorflow.org/}}, que juntas fornecem
implementações de redes neurais já prontas para uso. A partir dessas 
duas bibliotecas, o problema a ser resolvido será o de classificação
de um conjunto de dados específico.

Esse conjunto de dados reúne informações de 1429 proteínas, descritas
por 8 atributos (números reais). Para cada uma dessas proteínas, a sua
classe se refere à parte da célula em que a proteína se encontra.
Ao todo, existem 7 classes possíveis, descritas na Tabela
\ref{tab:classes}.

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		\textbf{Classe} & \textbf{Descrição} \\ \hline
		\textbf{CYT} & Citoplasma \\ \hline
		\textbf{MIT} & Mitocôndria \\ \hline
		\textbf{ME1} & Uma membrana específica da célula \\ \hline
		\textbf{ME2} & Uma membrana específica da célula \\ \hline
		\textbf{ME3} & Uma membrana específica da célula \\ \hline
		\textbf{EXC} & Exterior da célula \\ \hline
		\textbf{NUC} & Núcleo da célula \\ \hline
	\end{tabular}
	\caption{\label{tab:classes} Classes que descrevem a posição
	das proteínas em uma célula.}
\end{table}

Portanto, a rede neural criada será alimentada com os dados dessa base e,
ao longo do tempo, tentará aprender os padrões que determinam a saída
da mesma, isto é, dado um conjunto de 8 atributos de uma proteína, a
rede deve dizer qual é a posição que essa proteína ocupa na célula (
representada pela classe, dentre as 7 descritas acima).

\section{MODELAGEM}

A modelagem do problema de classificação em questão, utilizando redes
neurais implementadas através da biblioteca Keras com Tensorflow é 
mostrada nessa seção.

\subsection{Arquitetura}

Para modelar esse problema, o primeiro passo é determinar qual o tipo
da rede neural a ser construída - existem vários tipos de arquitetura
de redes neurais diferentes.

Para o trabalho em questão, optou-se por simplicidade em termos de
representação, o que, por sua vez, acarreta em maior controle sobre 
a estrutura da rede e de seu funcionamento. Dessa forma, a arquitetura
escolhida foi a \textit{Multilayer Perceptron - MLP} (Perceptron de
múltiplas camadas) -, que é uma versão da rede \textit{Perceptron} 
generalizada para conter múltiplas camadas escondidas de neurônios.
A Figura \ref{fig:mlp} mostra a estrutura da rede MLP.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=1\textwidth]{mlp.jpg}
  \caption{Estrutura da rede \textit{Multilayer Perceptron}. Vemos
  que, além das camadas de entrada e saída, a rede também pode
  apresentar um número arbitrário de camadas escondidas de neurônios.
  O número de neurônios em cada camada também pode ser escolhido
  arbitrariamente.}
  \label{fig:mlp}
\end{figure}

O número de camadas escondidas e número de neurônios em cada camada
utilizados no trabalho foram definidos experimentalmente, como mostrado
na Seção \ref{sec:exp}.

De forma geral, temos que a saída que um neurônio produz consiste na
soma ponderada (pelos pesos) de suas entradas, além de um valor de
\textit{bias}.

\begin{displaymath}
	Saida = \sum_{} (Pesos * Entradas) + Bias
\end{displaymath}

Além disso, essa saída passa por uma função de ativação antes de 
servir como entrada para os neurônios da camada seguinte. Essa
função de ativação determina se e quanto um neurônio deve contribuir
na rede, de acordo com os valores que gera.

\subsection{Inicialização de Pesos}

Uma decisão importante é a de como inicializar os pesos na rede. Sabemos
que se uma camada escondida tem um grande número de entradas, pequenas
mudanças nos pesos podem causar grandes alterações nas saídas dessa
camada. Uma forma de contornar isso é tornar os pesos iniciais da rede
proporcionais ao número de entradas. Para esse trabalho, optou-se por
inicializar os pesos proporcionalmente à raiz quadrada do número de
entradas nas camadas. Na biblioteca Keras, pode-se fazer isso adicionando
o argumento \textit{kernel\_initializer='lecun\_uniform'} ao construtor
de uma nova camada.

\subsection{Funções de Ativação}

Como mencionado, o processo de ativar um neurônio é fundamental para o
funcionamento correto da rede neural artificial. Dessa forma, é uma
decisão importante escolher qual função de ativação utilizar nas camadas
da rede. Existem muitas opções e a escolha deve levar em consideração
o tipo de problema a ser resolvido, além dos conhecimentos sobre os 
padrões de entrada\cite{principe2000neural}. Para o trabalho em questão, duas funções foram escolhidas, uma para as camadas escondidas e uma
para a camada de saída.

Para camadas escondidas, a função ReLU foi escolhida, uma vez que
preserva algumas propriedades interessantes de funções lineares e
faz com que a otimização com descida do gradiente seja fácil
\cite{Goodfellow-et-al-2016}.

\begin{equation}
	RELU(x) = 
	\begin{cases}
		0, & \text{if} ~ x < 0 \\
		1, & \text{if} ~ x \geq 0
	\end{cases}
\end{equation}

Já para a camada de saída, a função escolhida foi a Sotfmax, que 
apresenta resultados geralmente bons para problemas de classificação
multi classe. Essa função transforma as saídas de cada neurônio
para um valor entre $ 0 $ e $ 1 $, como uma função sigmoide. Além
disso, ela também faz com que a soma total das saídas seja igual a 
$ 1 $.

\subsection{Função de Custo}

A rede implementada no trabalho utiliza o conceito de
\textit{back-propagation}, com o qual os erros da saída da camada
de saída são passados de volta para os neurônios internos, que usam
esses erros para calcular seus próprios erros e atualizar seus pesos.
Esse algoritmo é baseado na otimização de uma função de custo através
do método de descida do gradiente. Dessa forma, é também uma decisão
de implementação escolher a função de custo do algoritmo. Para esse
trabalho, a função escolhida foi a \textit{cross-entropy}

\subsection{Validação Cruzada}

A fim de garantir que os resultados de generalização da rede não estejam
sendo obtidos ao acaso, foi implementado um sistema de validação cruzada
de 3 partições. Nesse sistema, o conjunto de dados de entrada é separado
em 3 partes, sendo que, a cada momento, duas delas são usadas para
treino e a parte restante para teste.

\subsection{Codificação da Saída}

Tendo em vista que os dados de entrada apresentam as classes de saída
como strings, foi necessário transformá-las para alimentar a rede neural.
Essas strings que representam as classes foram codificadas utilizando
o sistema de variáveis categóricas distribuídas. Dessa forma, cada uma
delas foi transformada em um vetor de zeros e uns.

\section{ESTRUTURA DO PROJETO E EXECUÇÃO}

O trabalho foi implementado utilizando-se a linguagem Python 3. Como já
mencionado, as redes neurais artificiais foram criadas através da
biblioteca Keras com Tensorflow.

O projeto está estruturado em $ 4 $ diretórios, como definidos abaixo:

\begin{itemize}
	\item \textbf{doc:} Contém a documentação do trabalho.
	\item \textbf{src:} Arquivo executável que lê os dados de entrada
	e cria a rede neural artificial com base nos argumentos passados
	na linha de comando para resolver o problema de classificação.
	\item \textbf{input:} Base de dados de entrada.
	\item \textbf{tests:} Contém os resultados dos testes executados
	durante a fase de experimentação.
\end{itemize}

Para executar o programa, basta executar o seguinte comando no
diretório raiz do projeto:

\begin{center}
	tp3.py [-h] [-e EPOCHS] [-l HLAYERS] [-n NEURONS] [-b BATCHSIZE]
	              [-s RSEED] [-r LRATE] [-d LRDECAY]
	              arquivo\_entrada arquivo\_saida
\end{center}

\begin{itemize}
	\item \textbf{Argumentos posicionais:}

	\begin{itemize}
		\item input\_filename: Nome do arquivo de entrada.
	 	\item output\_filename: Nome do arquivo de saída.
	\end{itemize}

	\item \textbf{Argumentos opcionais:}

	\begin{itemize}
		\item -h, --help: Mostra uma mensagem de ajuda e termina
		execução.
		\item -e EPOCHS: Executa o aprendizado da rede neural artificial
		por um número EPOCHS de épocas.
		\item -l HLAYERS: Define o número de camadas escondidas como 
		HLAYERS.
		\item -n NEURONS: Faz com que cada camada escondida tenha
		um número NEURONS de neurônios.
		\item -b BATCHSIZE: Define BATCHSIZE como o tamanho dos
		batches usados no treinamento da rede.
		\item -r LRATE: Define a taxa de aprendizado da rede como LRATE.
		\item -d LRDECAY: Define a taxa de decaimento da taxa de
		aprendizado como LRDECAY.
		\item -s RSEED: Define RSEED como a semente para geração de 
		números aleatórios durante a execução do programa.
	\end{itemize}
\end{itemize}

\section{EXPERIMENTOS} \label{sec:exp}



\section{CONCLUSÃO}



\section{REFERÊNCIAS}

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
